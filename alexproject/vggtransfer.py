# -*- coding: utf-8 -*-
"""VGGtransfer

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/151e2N_Y4WqV6GRGqybsq_qxTIGu9lRa3
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

import os
# %matplotlib inline

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras import optimizers
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D
from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation
from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.applications.resnet50 import ResNet50 as PretrainedModel, preprocess_input

from IPython.display import SVG, Image
import tensorflow as tf

import math
import numpy as np
import pandas as pd

# import scikitplot
import seaborn as sns
from matplotlib import pyplot

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report

from keras.utils import np_utils
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image

train_path = 'train-data/train'
valid_path = 'train-data/test'


# width_shift_range=0.1, height_shift_range=0.1

img_size = 96
batch_size = 64
datagen_train = ImageDataGenerator(
    width_shift_range=0.15,
    height_shift_range=0.15,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    preprocessing_function=preprocess_input
)
train_generator = datagen_train.flow_from_directory(
    train_path,
    target_size=(img_size, img_size),
    # color_mode='grayscale',
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True
)

datagen_validation = ImageDataGenerator(preprocessing_function=preprocess_input)
validation_generator = datagen_validation.flow_from_directory(
    valid_path,
    target_size=(img_size, img_size),
    # color_mode='grayscale',
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=True,
)

from keras import regularizers

ptm = PretrainedModel(
    input_shape=[img_size, img_size, 3],
    weights='imagenet',
    include_top=False)

x = Flatten()(ptm.output)

x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)

x = Dropout(0.5)(x)
x = Dense(512, activation='relu')(x)
x = BatchNormalization()(x)

x = Dense(7, activation='softmax', kernel_initializer='random_uniform', bias_initializer='random_uniform',
          bias_regularizer=regularizers.l2(0.01), name='predictions')(x)

# opt=optimizers.Nadam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam')
opt = optimizers.RMSprop(learning_rate=0.0001)
model = Model(inputs=ptm.input, outputs=x)
model.compile(
    loss='categorical_crossentropy',
    optimizer=opt,
    metrics=['accuracy']
)
model.summary()

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    min_delta=0.00005,
    patience=11,
    verbose=1,
    restore_best_weights=True,
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_accuracy',
    factor=0.5,
    patience=7,
    min_lr=1e-7,
    verbose=1,
)

callbacks = [
    early_stopping,
    lr_scheduler,
]

# optims = [
#     optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),
#     optimizers.Adam(0.001),
# ]

epochs = 100

steps_per_epoch = train_generator.n // train_generator.batch_size

validation_steps = validation_generator.n // validation_generator.batch_size

history = model.fit(
    x=train_generator,
    steps_per_epoch=steps_per_epoch,
    epochs=epochs,
    validation_data=validation_generator,
    validation_steps=validation_steps,
    callbacks=callbacks,
)

scores = model.evaluate(validation_generator, verbose=0)
print("Accuracy is %.2f%%" % (scores[1] * 100))

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='val_acc')
plt.legend()

# import cv2
# from tensorflow.keras.preprocessing import image
# import numpy as np
#
# emots = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'suprise']
# filename = 'happy.jpeg'
# plt.imshow(image.load_img(filename))
# plt.show()
# img = cv2.imread(filename)
# img = cv2.resize(img, (img_size, img_size))
# img = np.reshape(img, [1, img_size, img_size, 3])
# classes = model.predict([img])
# print(emots[np.argmax(classes[0])])
#
model.save('affModal.h5')
#
#
# # model2 = tf.keras.models.load_model('mymodal.h5')
# # scores=model2.evaluate(validation_generator,verbose=0)
# # print("Accuracy is %.2f%%" %  (scores[1]*100))
#
# from sklearn.metrics import confusion_matrix
# import itertools
#
#
# def plot_confusion_matrix(cm, classes,
#                           normalize=False,
#                           title='Confusion matrix',
#                           cmap=plt.cm.Blues):
#     """
#     This function prints and plots the confusion matrix.
#     Normalization can be applied by setting `normalize=True`.
#     """
#     if normalize:
#         cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
#         print("Normalized confusion matrix")
#     else:
#         print('Confusion matrix, without normalization')
#
#     print(cm)
#
#     plt.imshow(cm, interpolation='nearest', cmap=cmap)
#     plt.title(title)
#     plt.colorbar()
#     tick_marks = np.arange(len(classes))
#     plt.xticks(tick_marks, classes, rotation=45)
#     plt.yticks(tick_marks, classes)
#
#     fmt = '.2f' if normalize else 'd'
#     thresh = cm.max() / 2.
#     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
#         plt.text(j, i, format(cm[i, j], fmt),
#                  horizontalalignment="center",
#                  color="white" if cm[i, j] > thresh else "black")
#
#     plt.tight_layout()
#     plt.ylabel('True label')
#     plt.xlabel('Predicted label')
#     plt.show()
#
#
# p_test = model.predict(validation_generator).argmax(axis=1)
# cm = confusion_matrix(validation_generator.labels, p_test)
# plot_confusion_matrix(cm, list(range(7)))
#
# misclassified_idx = np.where(p_test != validation_generator.labels)[0]
# i = np.random.choice(misclassified_idx)
# plt.imshow(image.load_img(validation_generator.filepaths[i]))
# plt.title("True label: %s Predicted: %s" % (emots[validation_generator.labels[i]], emots[p_test[i]]));
#
# emots = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'suprise']
# emotsCounter = {'angry': 0, 'disgust': 0, 'fear': 0, 'happy': 0, 'neutral': 0, 'sad': 0, 'suprise': 0}
# # dirname="finalset/test/fear/"
# for emot in emots:
#     dirname = "finalset/test/{0}/".format(emot)
#     for filename in os.listdir(dirname):
#         img_size = 96
#         # img = cv2.imread(directory+filename,cv2.IMREAD_GRAYSCALE)
#         # plt.imshow(image.load_img(dirname+filename))
#         # plt.show()
#         img = cv2.imread(dirname + filename)
#         img = cv2.resize(img, (img_size, img_size))
#         img = np.reshape(img, [1, img_size, img_size, 3])
#         classes = model.predict([img])
#         emotsCounter[emots[np.argmax(classes[0])]] += 1
#
#     print('for {0} res is:'.format(emot), emotsCounter)
#     emotsCounter = {'angry': 0, 'disgust': 0, 'fear': 0, 'happy': 0, 'neutral': 0, 'sad': 0, 'suprise': 0}
